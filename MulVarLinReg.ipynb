{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Die multiple, lineare Regressionsanalyse\n",
    "Ein JupyterNotebook zur Beantwortung der wichtigsten Kernfragen:\n",
    "- Wie gut beschreibt das Regressionsmodell die Situation?\n",
    "- Kann ein (signifikanter) Einfluß der Merkmale auf die abhängige Variable belegt werden?\n",
    "- Wie unabhängig sind Einflussfaktoren voneinander?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56de6445d6c449378a449f5322e319f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Gebrauchtwagen', style=ButtonStyle()), Button(description='Immobilie', styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44dd058fcc7c4c1599cad7c81b531fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bitte ein Beispiel auswählen oder die Vorlage 12x5 zur Eingabe eigener Daten nutzen.\n",
    "# Erforderliche Python-Pakete\n",
    "%pip install ipywidgets ipython qgridnext pandas numpy scikit-learn scipy nbconvert pandoc>/dev/null 2>&1\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox\n",
    "from IPython.display import display, clear_output\n",
    "import qgridnext as qgrid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import scipy.stats\n",
    "from scipy.stats import f, t\n",
    "\n",
    "# Beispiel: “Arbeitsmotivation mit mehreren Pradiktoren”\n",
    "daten_arbeit = {\n",
    "    'i': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,14,15,16,17,18,19,20,21,22,23,24,25],\n",
    "    'y': [32, 14, 12, 27, 20, 13, 17, 8, 22, 19, 25, 23,17,22,19,27,26,20,11,24,19,19,22,24,17],\n",
    "    'x1': [36, 30, 19, 42, 14, 12, 17, 4, 32, 15, 38, 24,28,36,18,40,30,27,18,32,33,33,27,30,37],\n",
    "    'x2': [30, 11, 15, 16, 22, 16, 20, 5, 20, 13, 5, 6,11,4,26,27,28,11,23,18,9,22,28,32,8],\n",
    "    'x3': [20, 30, 15, 39, 5, 6, 12, 0, 35, 8, 34, 26,32,26,12,36,27,26,13,19,25,30,18,21,11],\n",
    "    'x4': [20, 7, 8, 13, 22, 11, 11, 16, 20, 13, 21, 9,10,16,6,12,18,10,11,15,6,5,17,11,2],\n",
    "    'x5': [3100, 2600, 3200, 2500, 3700, 2600, 2500, 3800, 3500, 3100, 3600, 2600,2600,2500,2500,2500,3000,2600,2800,2700,2400,2600,4000,2700,2300],\n",
    "    'x6': [34, 39, 42, 43, 42, 36, 41, 23, 25, 29, 59, 45,30,52,40,42,38,35,42,48,38,36,45,44,32],\n",
    "    'x7': [29, 16, 13, 15, 29, 17, 18, 9, 21, 21, 27, 31,7,23,17,29,34,19,18,23,23,30,23,20,20],\n",
    "    'x8': [69, 47, 32, 63, 38, 39, 44, 31, 40, 57, 53, 54,45,56,54,44,43,46,31,51,37,39,52,41,44],\n",
    "    'x9': [66, 36, 17, 49, 62, 51, 55, 33, 55, 56, 67, 62, 26,64,55,62,64,55,43,53,65,39,54,47,41]\n",
    "}\n",
    "\n",
    "daten_auto = {\n",
    "    'i': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,14],\n",
    "    'y': [19990, 20990, 21475, 23411, 23890, 25980, 28689, 31750, 34380, 34460, 34830, 34960, 35411, 35930],\n",
    "    'x1': [8710, 9890, 5425, 10419, 8590, 18062, 7960, 14100, 2637, 18000, 14900, 17250, 15949, 19888],\n",
    "    'x2': [11.7, 13.7, 13.7, 13.7, 14.7, 12.7, 13.7, 14.7, 14.7, 11.7, 10.7, 12.7, 12.7, 11.7],\n",
    "    'x3': [77, 77, 110, 110, 110, 110, 110, 110, 135, 135, 135, 135, 135, 135],\n",
    "    'x4': [5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 6, 6, 6],\n",
    "    'x5': [2, 0, 3, 3, 2, 2, 3, 3, 0, 0, 0, 0, 0, 0]\n",
    "}\n",
    "\n",
    "daten_immo = {\n",
    "    'i': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "    'y': [142000, 144000, 151000, 150000, 139000, 169000, 126000, 142900, 163000, 169000, 149000],\n",
    "    'x1': [2310, 2333, 2356, 2379, 2402, 2425, 2448, 2471, 2494, 2517, 2540],\n",
    "    'x2': [2, 2, 3, 3, 2, 4, 2, 2, 3, 4, 2],\n",
    "    'x3': [2, 2, 1.5, 2, 3, 2, 1.5, 2, 3, 4, 3],\n",
    "    'x4': [20, 3.6, 33, 43, 53, 23, 99, 34, 23, 55, 22]\n",
    "}                 \n",
    "\n",
    "daten_wahl = {\n",
    "    'i': ['Neuwied', 'Ahrweiler', 'Koblenz', 'Cochem', 'Kreuznach', 'Bitburg', 'Trier', 'Montabaur', 'Mainz', 'Worms', 'Frankenthal', 'Ludwigshafen', 'Neustadt - S', 'Kaiserslautern', 'Pirmasens', 'Sudpfalz'],\n",
    "    'y': [44.21, 50.13, 46.6 , 50.94, 39.1, 52.68, 44.82, 43.42, 40.86, 37.99, 39.71, 40.86, 46.48, 37.68, 42.79, 45.09 ],\n",
    "    'x1': [55.55, 81.99, 73.14, 70.78, 32.6, 91.4 , 87.97, 50.76, 51.36, 32.81, 31.98, 38.01, 45.61, 34.89, 45.98, 55.07 ],\n",
    "    'x2': [ 10.1,  9.6 ,  9.3 ,  10.8, 12  ,  9.3 ,  9.9 ,  8.4 ,  8.3 ,  9.6 , 10.6 , 10.1 ,  9.3 , 14.4 , 14.4 , 10.1  ]    \n",
    "}\n",
    "\n",
    "daten_dummy = {\n",
    "    'i':  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    'y':  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    'x1': [0, 0, 0, 0, 0, 0, 0, 0, 0,  0,  0,  0],\n",
    "    'x2': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    'x3': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    'x4': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    'x5': [1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1]\n",
    "}                 \n",
    "\n",
    "global dfr\n",
    "dfr = pd.DataFrame()\n",
    "\n",
    "# Beispiel Funktionen\n",
    "def beispiel_1(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(\"y = Preis | x1 = Kilometer | x2 = Alter [Mon.] | x3 = Leistung [kW] | x4 = Schadstoffklasse | x5 = Ausstattung T/C/H\")\n",
    "        usesample(daten_auto)\n",
    "    \n",
    "def beispiel_2(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(\"y = Preis | x1 = Grundfläche (m²) | x2 = Büroräume | x3 = Eingänge | x4 = Alter (Jahre)\")\n",
    "        usesample(daten_immo)\n",
    "\n",
    "def beispiel_3(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(\"y = Motivation | x1 = Ehrgeiz       | x2 = Kreativität | x3 = Leistungsstreben\")\n",
    "        print(\"                 x4 = Hierarchie    | x5 = Lohn        | x6 = Arbeitsbedingungen\")\n",
    "        print(\"                 x7 = Lernpotential | x8 = Vielfalt    | x9 = Anspruch\")\n",
    "        print(\"siehe https://www.ruhr-uni-bochum.de/imperia/md/content/mathematik3/lehre/ss10/methodenlehre2/teil219062010.pdf\")\n",
    "        usesample(daten_arbeit)\n",
    "\n",
    "def beispiel_4(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(\"y = Wahlergebnis | x1 = Katholiken | x2 = Arbeitslose\")\n",
    "        print(\"Hypothesen: A: Je größer der Anteil der Katholiken, desto besser das Wahlergebnis.\")\n",
    "        print(\"            B: Je höher die Arbeitslosenquote, desto schlechter das Wahlergebnis.\")\n",
    "        print(\"siehe https://www.uni-koeln.de/wiso-fak/fisoz/Mitarbeiter/Best/S10.pdf\")\n",
    "        usesample(daten_wahl)\n",
    "        \n",
    "def beispiel_5(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(\"Bitte Daten einfügen und ggf. Zeilen löschen/hinzufügen.\")\n",
    "        usesample(daten_dummy)\n",
    "\n",
    "def usesample(data):\n",
    "    global dfr\n",
    "    dfr = pd.DataFrame(data)\n",
    "    if data == daten_dummy:\n",
    "        editMode = True\n",
    "    else:\n",
    "        editMode = False\n",
    "    global qgrid_widget\n",
    "    qgrid_widget = qgrid.show_grid(dfr, show_toolbar=editMode, column_definitions={ 'index': { 'maxWidth': 0, 'minWidth': 0, 'width': 0 }}) #, grid_options=gropts)\n",
    "    display(qgrid_widget)\n",
    "\n",
    "# Erstellen der Schaltflächen\n",
    "button1 = widgets.Button(description=\"Gebrauchtwagen\")\n",
    "button2 = widgets.Button(description=\"Immobilie\")\n",
    "button3 = widgets.Button(description=\"Arbeitsmotivation\")\n",
    "button4 = widgets.Button(description=\"Politbarometer\")\n",
    "button5 = widgets.Button(description=\"Vorlage 12x5\")\n",
    "\n",
    "# Zuweisen der Ereignis-Handler\n",
    "button1.on_click(beispiel_1)\n",
    "button2.on_click(beispiel_2)\n",
    "button3.on_click(beispiel_3)\n",
    "button4.on_click(beispiel_4)\n",
    "button5.on_click(beispiel_5)\n",
    "\n",
    "# Ausgabe-Widget für die Anzeige der Ergebnisse\n",
    "# Erstellen eines HBox-Widgets mit den Schaltflächen als Kinder\n",
    "buttons = HBox([button1, button2, button3,button4,button5])\n",
    "output = widgets.Output()\n",
    "\n",
    "# Anzeigen der Schaltflächen und des Ausgabe-Widgets\n",
    "display(buttons, output)\n",
    "dfr = pd.DataFrame(daten_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten aufbereiten\n",
    "df = qgrid_widget.get_changed_df()\n",
    "\n",
    "# Drop the 'i' column\n",
    "x_true = df.drop(columns=['i'], inplace=False)\n",
    "x_true.drop(columns=['y'], inplace=True)\n",
    "\n",
    "# Extract the 'y' column to a new DataFrame\n",
    "y_true = df[['y']].copy()\n",
    "\n",
    "# Drop the 'y' column from the original DataFrame\n",
    "#df.drop(columns=['y'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frage**: *Wie gut beschreibt das Regressionsmodell die Situation?*\n",
    "\n",
    "Die Güte der Modellanpassung wird durch das Bestimmtheitsmaß R² beschrieben. Es beschreibt welchen Anteil die Regression an der gesamten, beobachteten Varianz erklärt. Aus der Gesamtvarianz der Regression und der Varianz der Residuen wird ein F-Wert berechnet. Auf dessen Basis und der F-Verteilung ist eine Bewertung dahingehend möglich, ob die zwischen der _abhängigen_ und der _unabhängigen_ Variablen beobachtete Beziehung zufällig ist oder nicht.\n",
    "\n",
    "Sofern der Vertrauensbereich des Achsenabschnitts den Nullpunkt nicht einschließt, liegt ein zu berücksichtigender Offset vor.\n",
    "\n",
    "Die relative Verfahrensstandardabweichung Vxo wird zur besseren Vergleichbarkeit herangezogen (z.B. beim Vergleich von Prüfverfahren oder Laboren)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_cde8d td.col0 {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_cde8d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_cde8d_level0_col0\" class=\"col_heading level0 col0\" >R²</th>\n",
       "      <th id=\"T_cde8d_level0_col1\" class=\"col_heading level0 col1\" >F-Wert</th>\n",
       "      <th id=\"T_cde8d_level0_col2\" class=\"col_heading level0 col2\" >F-Vert</th>\n",
       "      <th id=\"T_cde8d_level0_col3\" class=\"col_heading level0 col3\" >Signifikanz</th>\n",
       "      <th id=\"T_cde8d_level0_col4\" class=\"col_heading level0 col4\" >Offset</th>\n",
       "      <th id=\"T_cde8d_level0_col5\" class=\"col_heading level0 col5\" >Vxo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_cde8d_row0_col0\" class=\"data row0 col0\" >0.8602</td>\n",
       "      <td id=\"T_cde8d_row0_col1\" class=\"data row0 col1\" >9.8433</td>\n",
       "      <td id=\"T_cde8d_row0_col2\" class=\"data row0 col2\" >3.6875</td>\n",
       "      <td id=\"T_cde8d_row0_col3\" class=\"data row0 col3\" >99.711282</td>\n",
       "      <td id=\"T_cde8d_row0_col4\" class=\"data row0 col4\" >Nein</td>\n",
       "      <td id=\"T_cde8d_row0_col5\" class=\"data row0 col5\" >10.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x795ccf6f0fd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kennzahlen des Regressionsmodells\n",
    "\n",
    "debugMode = False\n",
    "# Initialisieren Sie eine Instanz des LinearRegression-Objekts:\n",
    "model = LinearRegression()  #fit_intercept=True,copy_X=True)\n",
    "\n",
    "# Trainieren Sie das Modell durch Anpassen der Regressionsgerade an die Daten:\n",
    "model.fit(x_true,y_true)          \n",
    "y_pred = model.predict(x_true)\n",
    "\n",
    "# k = Anz. Prädikatoren // m = ßn // n= Anz. Datensätze\n",
    "n=len(x_true); \n",
    "m=model.coef_.flatten()\n",
    "k=model.rank_\n",
    "df=n-k-1\n",
    "\n",
    "# Regressionskoeffizienten (beta_i)\n",
    "if debugMode:\n",
    "    print(\"=== CHECK ===\")\n",
    "    print(\"SPSS=\\t0,053    0,206\t0,165\t-0,031\t 0,000\t0,246\t0,049\t0,153\t0,193\t-3,842\")\n",
    "    print(\"mx|b=\\t0,053\t0,206\t0,165\t-0,031\t-0,001\t0,246\t0,049\t0,153\t0,193\t-3,842\")\n",
    "beta  = m                   # model.coef_\n",
    "beta0 = model.intercept_[0] # model.intercept_\n",
    "\n",
    "result=f\"ß{k}...ß1\"\n",
    "for value in beta[::-1]:\n",
    "    result += f\"\\t{value:.3f}\"    \n",
    "result += f\"\\t{beta0:.3f}\"\n",
    "if debugMode:\n",
    "    print(result)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y_true - y_pred\n",
    "\n",
    "# Calculate the sum of squares of residuals (SSR)\n",
    "SSR = np.sum(residuals**2,axis=0).iloc[0]\n",
    "\n",
    "# Calculate the sum of squares of regression (SSReg)\n",
    "y_mean = np.mean(y_true)\n",
    "SSReg = np.sum((y_pred - y_mean)**2,axis=0)[0]\n",
    "SST = SSReg + SSR       # Total sum of squares (SST)\n",
    "Rs = SSReg / SST        # R²\n",
    "s2yx = (SSR / df)  # Residual variance (s²yx)\n",
    "if debugMode:\n",
    "    print(\"-------------\")\n",
    "    print(\"R²\\tSPSS|EXCEL|NB = 92.95|92.95|%.2f\" % (Rs*100))\n",
    "    print(\"Syx|Sey\\tSPSS|EXCEL|NB = 1.891|1.891|%.3f\" % np.sqrt(s2yx))\n",
    "\n",
    "# Synonym: s2yx == MSE\n",
    "MSE = float(SSR / df)              # Calculate the residual variance (mean squared error, MSE)\n",
    "F_stat = float((SSReg / k) / MSE)  # F-Statistik\n",
    "if debugMode:\n",
    "    print(\"-------------\")\n",
    "    print(\"F\\tSPSS|EXCEL|NB = 21.972|21.972|%.3f\" % F_stat)\n",
    "    print(\"df\\tSPSS|EXCEL|NB = 15|15|%d\" % df)\n",
    "    print(\"-------------\")\n",
    "FK=scipy.stats.f.ppf(1-0.05, k,n-k-1)\n",
    "if debugMode:\n",
    "    print(\"OK Fkrit = %.4f\" % FK)\n",
    "    print(\"ssreg\\tSPSS|EXCEL|NB = 707.309|707.309|%.3f\" % SSReg)\n",
    "SSRes = np.sum(residuals**2,axis=0).iloc[0]\n",
    "if debugMode:\n",
    "    print(\"ssres\\tSPSS|EXCEL|NB = 56.691|56.691|%.3f\" % SSRes)  \n",
    "    print(\"-------------\")\n",
    "    #Use float(ser.iloc[0]\n",
    "\n",
    "    # Calculate the standard errors of coefficients (S_xi)\n",
    "    print(f\"SE{k}..SE1 SPSS \\t0,058   0,052\t0,098\t0,054\t0,001\t0,148\t0,065\t0,049\t0,081\t5,052\")\n",
    "    print(f\"SE{k}..SE1 EXCEL\\t0,058\t0,052\t0,098\t0,054\t0,001\t0,148\t0,065\t0,049\t0,081\t5,052\")\n",
    "X = np.hstack([np.ones((x_true.shape[0], 1)), x_true])  # Add a column of ones for the intercept\n",
    "X_transpose_X_inv = np.linalg.inv(np.dot(X.T, X))       # Inverse of (X^T * X)\n",
    "SEcoeff = np.sqrt(np.diagonal(MSE * X_transpose_X_inv))\n",
    "\n",
    "result=f\"SE{k}..SE1 NB\"\n",
    "for value in SEcoeff[::-1]:\n",
    "    result += f\"\\t{value:.3f}\"    \n",
    "if debugMode:\n",
    "    print(result)\n",
    "    print(\"-------------\")\n",
    "\n",
    "SE_intercept = np.sqrt(X_transpose_X_inv[0, 0] * MSE)\n",
    "if debugMode:\n",
    "    print(f\"SEintercept = {SE_intercept:.3f}\")\n",
    "# Bestimmen des t-Werts für das gewünschte Konfidenzniveau (z.B. 95%)\n",
    "alpha = 0.05  # Für ein 95% Konfidenzniveau\n",
    "t_value = t.ppf(1 - alpha/2, df)\n",
    "\n",
    "# Berechnen des Konfidenzintervalls des Achsenabschnitts\n",
    "CI_lower = beta0 - t_value * SE_intercept\n",
    "CI_upper = beta0 + t_value * SE_intercept\n",
    "# Überprüfen, ob das Konfidenzintervall Null einschließt\n",
    "einschliesst_null = CI_lower <= 0 and CI_upper >= 0\n",
    "offset = \"Nein\" if einschliesst_null else \"Ja\"\n",
    "Vxo=np.sqrt(s2yx)/np.mean(y_true)*100\n",
    "if debugMode:\n",
    "    print(f\"Vertrauensbereich des Achsenabschnitts (95%): {CI_lower:.3f}, {CI_upper:.3f}\")\n",
    "    print(f\"Vxo = {Vxo:.3f}\")\n",
    "\n",
    "if debugMode:\n",
    "    for wert in y_pred: # Fehler der vorhergesagten Y-Werte\n",
    "        print(np.sqrt(s2yx)*t_value*np.sqrt(1+1/n+(wert-y_true['y'].mean())**2/SSReg))\n",
    "\n",
    "# p-Wert berechnen\n",
    "# Der resultierende p-Wert gibt das Signifikanzniveau der Regression an. Ein kleiner p-Wert (z.B.\n",
    "# weniger als 0.05) weist darauf hin, dass die Nullhypothese (dass alle Regressionskoeffizienten \n",
    "# gleich null sind) abgelehnt werden kann, was darauf hinweist, dass das Modell signifikant ist.\n",
    "from scipy.stats import f\n",
    "p_value = f.cdf(F_stat, k, n-k-1)*100\n",
    "\n",
    "regt = pd.DataFrame()\n",
    "regt['R²'] = [Rs]\n",
    "regt['F-Wert'] = [F_stat]\n",
    "regt['F-Vert'] = [FK]\n",
    "regt['Signifikanz'] = [p_value]\n",
    "regt['Offset'] = [offset]\n",
    "regt['Vxo'] = [Vxo]\n",
    "\n",
    "styled_regt = regt.style.format({\n",
    "    'R²': '{:.4f}',          # Beschränkt die Anzahl der Dezimalstellen auf 2 für die Spalte 'Beta'\n",
    "    'F-Wert': '{:.4f}',      # Beschränkt die Anzahl der Dezimalstellen auf 2 für die Spalte 'Std.fehler'\n",
    "    'F-Vert': '{:.4f}',      # Beschränkt die Anzahl der Dezimalstellen auf 2 für die Spalte 'rel.Beta'\n",
    "    'Signifikanz': '{:.6f}', # Beschränkt die Anzahl der Dezimalstellen auf 2 für die Spalte 'rel.Beta'\n",
    "    'Vxo': '{:.2f}'          # Beschränkt die Anzahl der Dezimalstellen auf 2 für die Spalte 'rel.Beta'\n",
    "}).set_table_styles(         # Center align the 'Prädikator' column\n",
    "    [{'selector': 'td.col0', 'props': [('text-align', 'center')]}\n",
    "]).hide(axis='index')        # Hide the index column\n",
    "\n",
    "# Anzeigen des formatierten DataFrames\n",
    "styled_regt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kennzahlen des Regressionskoeffizienten\n",
    "\n",
    "# Standardabweichungen der unabhängigen Variablen (S_xi)\n",
    "S_x = x_true.std()\n",
    "\n",
    "# Standardabweichung der abhängigen Variablen (S_y)\n",
    "S_y = y_true.std()\n",
    "\n",
    "# Berechnung der standardisierten Regressionskoeffizienten (b_i)\n",
    "sse = m * S_x.values / S_y.values\n",
    "\n",
    "if debugMode:\n",
    "    print(f\"SSE{k}..SSE1 SPSS \\t0,058   0,052\t0,098\t0,054\t0,001\t0,148\t0,065\t0,049\t0,081\t5,052\")\n",
    "result=f\"SSE{k}..SSE1 NB\\t\"\n",
    "for value in SEcoeff[::-1]:\n",
    "    result += f\"\\t{value:.3f}\"    \n",
    "if debugMode:\n",
    "    print(result)\n",
    "    print(\"-------------\")\n",
    "\n",
    "#print(\"SSECoeff=\",SEcoeff[1:])\n",
    "#print(\"sse=\",sse)\n",
    "#print(\"model.coef_=\",model.coef_    )\n",
    "#print(model.coef_   )\n",
    "\n",
    "# Calculate the mean of the independent variables\n",
    "x_mean = np.mean(x_true, axis=0)\n",
    "\n",
    "# Calculate the sum of squares of the independent variables\n",
    "x_sum_squares = np.sum((x_true - x_mean)**2, axis=0)\n",
    "\n",
    "# Calculate the standard error of the intercept\n",
    "SE_intercept = np.sqrt(MSE * (1/n + np.sum(x_mean**2 / x_sum_squares)))\n",
    "if debugMode:\n",
    "    print(\"sey=\",SE_intercept)\n",
    "\n",
    "# Calculate the normalized correlation coefficients\n",
    "sen = np.abs(sse) #see / (SEcoeff[1:])) #SEcoeff[1:] * 1) # (see * SE_intercept)) # SE_intercept / see)\n",
    "\n",
    "# SE_normalized contains the normalized correlation coefficients\n",
    "if debugMode:\n",
    "    print(f\"sen{k}..sen1 SPSS \\t0.337   0.234   0.095   0.235   -0.077  -0.045  0.199   0.354   0.124\")\n",
    "result=f\"sen{k}..sen NB\\t\"\n",
    "for value in sen: #[::-1]:\n",
    "    result += f\"\\t{value:.3f}\"    \n",
    "if debugMode:\n",
    "    print(result)\n",
    "    print(\"-------------\")\n",
    "\n",
    "p_significance_values = 100-(1 - t.cdf(abs(abs(np.array(m) / SEcoeff[1:])), n-k-1)) * 200\n",
    "if debugMode:\n",
    "    print(p_significance_values)\n",
    "\n",
    "alpha = 0.05  # Beispielwert für ein 95% Konfidenzintervall\n",
    "\n",
    "# Berechne den kritischen t-Wert\n",
    "t_critical = t.ppf(1 - 0.05/2, df)\n",
    "\n",
    "if debugMode:\n",
    "    print(\"t_crit=\",t_critical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Koeffzienten-Übersicht\n",
    "**Frage**: *Kann ein (signifikanter) Einfluß der Merkmale (x<sub>n</sub>) auf die abhängige Variable (y) belegt werden?*\n",
    "\n",
    "Die folgenden Übersicht zeigt die Regressionskoeffizienten (\"Beta\"), deren Standardfehler und andere Infos zu den einzelnen Prädikatoren (x<sub>n</sub>).\n",
    "Die Spalte \"rel.Beta\" enthält die **standardisierte Regressionskoeffizienten**. Durch die Standardisierung werden Skaleneffekte der einzelnen Faktoren beseitigt. Somit lassen sich die Regressionskoeffizienten besser miteinander vergleichen.\n",
    "Die Spalte \"Signifikanz\" gibt an, wie signifikant der Einfluss des jeweilige Prädikators auf die Regression ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y =  0.2582*x1 +487.4888*x2 +223.6825*x3 -622.9611*x4 -1067.0129*x5 -1805.9536 (t=2.306)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a36d6 td.col0 {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_a36d6_row0_col4, #T_a36d6_row1_col4, #T_a36d6_row3_col4, #T_a36d6_row4_col4 {\n",
       "  color: red;\n",
       "}\n",
       "#T_a36d6_row2_col4 {\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a36d6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_a36d6_level0_col0\" class=\"col_heading level0 col0\" >Prädiktor</th>\n",
       "      <th id=\"T_a36d6_level0_col1\" class=\"col_heading level0 col1\" >Beta</th>\n",
       "      <th id=\"T_a36d6_level0_col2\" class=\"col_heading level0 col2\" >Std.fehler</th>\n",
       "      <th id=\"T_a36d6_level0_col3\" class=\"col_heading level0 col3\" >rel.Beta</th>\n",
       "      <th id=\"T_a36d6_level0_col4\" class=\"col_heading level0 col4\" >Signifikanz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_a36d6_row0_col0\" class=\"data row0 col0\" >x1</td>\n",
       "      <td id=\"T_a36d6_row0_col1\" class=\"data row0 col1\" >0.2582</td>\n",
       "      <td id=\"T_a36d6_row0_col2\" class=\"data row0 col2\" >0.2422</td>\n",
       "      <td id=\"T_a36d6_row0_col3\" class=\"data row0 col3\" >22.3</td>\n",
       "      <td id=\"T_a36d6_row0_col4\" class=\"data row0 col4\" >68.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a36d6_row1_col0\" class=\"data row1 col0\" >x2</td>\n",
       "      <td id=\"T_a36d6_row1_col1\" class=\"data row1 col1\" >487.4888</td>\n",
       "      <td id=\"T_a36d6_row1_col2\" class=\"data row1 col2\" >856.0997</td>\n",
       "      <td id=\"T_a36d6_row1_col3\" class=\"data row1 col3\" >10.1</td>\n",
       "      <td id=\"T_a36d6_row1_col4\" class=\"data row1 col4\" >41.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a36d6_row2_col0\" class=\"data row2 col0\" >x3</td>\n",
       "      <td id=\"T_a36d6_row2_col1\" class=\"data row2 col1\" >223.6825</td>\n",
       "      <td id=\"T_a36d6_row2_col2\" class=\"data row2 col2\" >51.3001</td>\n",
       "      <td id=\"T_a36d6_row2_col3\" class=\"data row2 col3\" >74.2</td>\n",
       "      <td id=\"T_a36d6_row2_col4\" class=\"data row2 col4\" >99.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a36d6_row3_col0\" class=\"data row3 col0\" >x4</td>\n",
       "      <td id=\"T_a36d6_row3_col1\" class=\"data row3 col1\" >-622.9611</td>\n",
       "      <td id=\"T_a36d6_row3_col2\" class=\"data row3 col2\" >3011.5225</td>\n",
       "      <td id=\"T_a36d6_row3_col3\" class=\"data row3 col3\" >-4.7</td>\n",
       "      <td id=\"T_a36d6_row3_col4\" class=\"data row3 col4\" >15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a36d6_row4_col0\" class=\"data row4 col0\" >x5</td>\n",
       "      <td id=\"T_a36d6_row4_col1\" class=\"data row4 col1\" >-1067.0129</td>\n",
       "      <td id=\"T_a36d6_row4_col2\" class=\"data row4 col2\" >804.5494</td>\n",
       "      <td id=\"T_a36d6_row4_col3\" class=\"data row4 col3\" >-23.9</td>\n",
       "      <td id=\"T_a36d6_row4_col4\" class=\"data row4 col4\" >77.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x795ccf58e560>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Übersicht der Koeffizienten\n",
    "coeft = pd.DataFrame() \n",
    "coeft['Prädiktor'] = model.feature_names_in_\n",
    "coeft['Beta'] = model.coef_.flatten().round(4)\n",
    "coeft['Std.fehler'] = SEcoeff[1:].round(4)\n",
    "coeft['rel.Beta'] = (sse*100).round(1)\n",
    "coeft['Signifikanz'] = p_significance_values.round(1)\n",
    "\n",
    "# Optimierter Datenframe\n",
    "#sign_prädiktoren = coeft[coeft['Signifikanz'] > 50]['Prädiktor'].values\n",
    "#print(sign_prädiktoren)\n",
    "#newdf = pd.DataFrame()\n",
    "#newdf['y'] = y_true ['y']\n",
    "#newdf = pd.concat([newdf, x_true[sign_prädiktoren]], axis=1)\n",
    "#modelndf = LinearRegression()  #fit_intercept=True,copy_X=True)\n",
    "#modelndf.fit(newdf[sign_prädiktoren],newdf['y'])\n",
    "#ndf_y_pred = modelndf.predict(newdf[sign_prädiktoren])\n",
    "#newdf[\"Y\\'\"] = ndf_y_pred\n",
    "#print(newdf)\n",
    "\n",
    "# Basisstring für die Formel\n",
    "formel = \"Y = \"\n",
    "\n",
    "# Füge jeden Prädiktor und seinen Beta-Koeffizienten zur Formel hinzu\n",
    "for index, row in coeft.iterrows():\n",
    "    beta_wert = f\"+{row['Beta']}\" if row['Beta'] > 0 and index > 0 else f\"{row['Beta']}\"\n",
    "    formel += f\" {beta_wert}*{row['Prädiktor']}\"\n",
    "\n",
    "# Überprüfe, ob ein Intercept vorhanden ist und füge ihn hinzu (angenommen, der Intercept ist im Modell gespeichert)\n",
    "if hasattr(model, 'intercept_'):\n",
    "    formel += f\" {model.intercept_.round(4)[0]}\"\n",
    "y_low = np.sqrt(s2yx)*t_value*np.sqrt(1+1/n+y_true['y'].mean()**2/SSReg)\n",
    "#formel += f\" > {y_low:.3f}\"\n",
    "formel += f\" (t={t.ppf(1-0.05/2, df):.3f})\" \n",
    "\n",
    "# Ausgabe der Formel\n",
    "print(formel)\n",
    "\n",
    "def highlight_significance(val):\n",
    "    if val < 95:\n",
    "        return 'color: red'  # Rot, wenn Signifikanz < 95\n",
    "    else:\n",
    "        return 'font-weight: bold'  # Fett, wenn Signifikanz >= 95\n",
    "\n",
    "# Anwenden der bedingten Formatierung auf die Spalte \"Signifikanz\"\n",
    "styled_coeft = coeft.style.map(highlight_significance, subset=['Signifikanz'])\n",
    "\n",
    "# Formatierung anwenden, um die Anzahl der Dezimalstellen zu beschränken\n",
    "styled_coeft = styled_coeft.format({\n",
    "    'Beta': '{:.4f}',           # Beschränkt die Anzahl der Dezimalstellen auf 2 für die Spalte 'Beta'\n",
    "    'Std.fehler': '{:.4f}',     # Beschränkt die Anzahl der Dezimalstellen auf 2 für die Spalte 'Std.fehler'\n",
    "    'rel.Beta': '{:.1f}',       # Beschränkt die Anzahl der Dezimalstellen auf 2 für die Spalte 'rel.Beta'\n",
    "    'Signifikanz': '{:.1f}'     # Beschränkt die Anzahl der Dezimalstellen auf 2 für die Spalte 'Signifikanz'\n",
    "}).set_table_styles(            # Center align the 'Prädikator' column\n",
    "    [{'selector': 'td.col0', 'props': [('text-align', 'center')]}\n",
    "]).hide(axis='index')           # Hide the index column\n",
    "\n",
    "# Anzeigen des formatierten DataFrames\n",
    "styled_coeft \n",
    "\n",
    "#qgrid_widget = qgrid.show_grid(coeft, show_toolbar=True, column_definitions={ 'index': { 'maxWidth': 0, 'minWidth': 0, 'width': 0 }},grid_options={'highlightSelectedRow': False})\n",
    "#qgrid_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frage**: Wie unabhängig sind Einflussfaktoren voneinander?\n",
    "\n",
    "Das Problem der Multikollinearität lässt sich grafisch ansprechend in einer Korrelationsmatrix der Prädikatoren darstellen. Ein hoher Wert am Schnittpunkt belegt die Kollinearität der vermeintlich \"unabhängigen\" Variabeln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kolinearität der Prädiktoren überprüfen\n",
    "correlation_matrix = x_true.corr()\n",
    "\n",
    "# Ausgabe der Korrelationsmatrix print(correlation_matrix)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "###\n",
    "# Maske erstellen, um die obere Dreieckshälfte auszublenden\n",
    "mask = np.tril(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Reihenfolge der Spalten umkehren\n",
    "#correlation_matrix = correlation_matrix.iloc[::1,::-1]\n",
    "\n",
    "# Heatmap erstellen\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.75})\n",
    "\n",
    "# Erstellen der Heatmap mit den verbleibenden Daten\n",
    "\n",
    "# x-Achse oben darstellen und Reihenfolge der Spalten umkehren\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.gca().xaxis.tick_top()\n",
    "plt.gca().tick_params(length=0)\n",
    "\n",
    "# Titel hinzufügen\n",
    "plt.title('Korrelationsmatrix der Prädiktoren', pad=20)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further reading:\n",
    "https://www.uni-trier.de/fileadmin/urt/doku/linreg/linreg.pdf "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
